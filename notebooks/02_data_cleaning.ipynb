{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce891ab-e026-45b8-8a52-5e0a10dd67f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö IMPORTING LIBRARIES\n",
      "----------------------------------------\n",
      "‚úÖ pandas: Data manipulation and analysis\n",
      "‚úÖ numpy: Numerical operations and handling missing values\n",
      "\n",
      "üìÅ LOADING DATASET\n",
      "----------------------------------------\n",
      "‚úÖ Dataset loaded successfully from: data/raw/student_performance.csv\n",
      "   Initial shape: (395, 33)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DATA CLEANING PIPELINE - Student Performance Dataset\n",
    "Author: Elys√©e NIYIBIZI\n",
    "Date: 05/01/2026\n",
    "\n",
    "Professional data cleaning workflow following industry best practices.\n",
    "This pipeline transforms raw data into analysis-ready format while\n",
    "maintaining data integrity and providing clear documentation.\n",
    "\n",
    "Dataset: Student Performance Data\n",
    "Objective: Clean, validate, and prepare data for machine learning\n",
    "\"\"\"\n",
    "\n",
    "# CELL 1: Import Libraries and Load Data\n",
    "# =======================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üìö IMPORTING LIBRARIES\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚úÖ pandas: Data manipulation and analysis\")\n",
    "print(\"‚úÖ numpy: Numerical operations and handling missing values\")\n",
    "\n",
    "# Load data from specified path structure\n",
    "print(\"\\nüìÅ LOADING DATASET\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/student_performance.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully from: data/raw/student_performance.csv\")\n",
    "    print(f\"   Initial shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: File not found. Please ensure:\")\n",
    "    print(\"   1. The 'data/raw/' directory exists\")\n",
    "    print(\"   2. 'student_performance.csv' is in that directory\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3e45ed-0e81-429d-bd8b-0b035c0abdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç INITIAL DATA ASSESSMENT\n",
      "============================================================\n",
      "\n",
      "1. DATA PREVIEW (First 5 Rows)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL 2: Initial Data Assessment\n",
    "# ===============================\n",
    "print(\"üîç INITIAL DATA ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. DATA PREVIEW (First 5 Rows)\")\n",
    "print(\"-\" * 40)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9149fe1d-ff52-42f9-b95c-599ef67dadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. DATASET STRUCTURE & DATA TYPES\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      395 non-null    object\n",
      " 1   sex         395 non-null    object\n",
      " 2   age         395 non-null    int64 \n",
      " 3   address     395 non-null    object\n",
      " 4   famsize     395 non-null    object\n",
      " 5   Pstatus     395 non-null    object\n",
      " 6   Medu        395 non-null    int64 \n",
      " 7   Fedu        395 non-null    int64 \n",
      " 8   Mjob        395 non-null    object\n",
      " 9   Fjob        395 non-null    object\n",
      " 10  reason      395 non-null    object\n",
      " 11  guardian    395 non-null    object\n",
      " 12  traveltime  395 non-null    int64 \n",
      " 13  studytime   395 non-null    int64 \n",
      " 14  failures    395 non-null    int64 \n",
      " 15  schoolsup   395 non-null    object\n",
      " 16  famsup      395 non-null    object\n",
      " 17  paid        395 non-null    object\n",
      " 18  activities  395 non-null    object\n",
      " 19  nursery     395 non-null    object\n",
      " 20  higher      395 non-null    object\n",
      " 21  internet    395 non-null    object\n",
      " 22  romantic    395 non-null    object\n",
      " 23  famrel      395 non-null    int64 \n",
      " 24  freetime    395 non-null    int64 \n",
      " 25  goout       395 non-null    int64 \n",
      " 26  Dalc        395 non-null    int64 \n",
      " 27  Walc        395 non-null    int64 \n",
      " 28  health      395 non-null    int64 \n",
      " 29  absences    395 non-null    int64 \n",
      " 30  G1          395 non-null    int64 \n",
      " 31  G2          395 non-null    int64 \n",
      " 32  G3          395 non-null    int64 \n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 102.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. DATASET STRUCTURE & DATA TYPES\")\n",
    "print(\"-\" * 40)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c542f1-28ee-4702-ab2b-5d7382ca19cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. MISSING VALUES CHECK\n",
      "----------------------------------------\n",
      "Total missing values: 0\n",
      "\n",
      "Missing values per column:\n",
      "‚úÖ No missing values found in any column\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. MISSING VALUES CHECK\")\n",
    "print(\"-\" * 40)\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Total missing values: {missing_values.sum()}\")\n",
    "print(\"\\nMissing values per column:\")\n",
    "missing_df = missing_values[missing_values > 0]\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found in any column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21648fd8-7a3e-449f-aabd-8e461060b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. DUPLICATE RECORDS CHECK\n",
      "----------------------------------------\n",
      "Duplicate rows found: 0\n",
      "Duplicate percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. DUPLICATE RECORDS CHECK\")\n",
    "print(\"-\" * 40)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows found: {duplicate_count}\")\n",
    "print(f\"Duplicate percentage: {(duplicate_count/len(df)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e009133e-6a80-4422-ae48-d14d9890c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ HANDLING MISSING VALUES\n",
      "============================================================\n",
      "\n",
      "STRATEGY FOR HANDLING MISSING DATA:\n",
      "----------------------------------------\n",
      "üìä NUMERICAL COLUMNS ‚Üí Fill with Median\n",
      "   ‚Ä¢ Why? Median is robust to outliers\n",
      "   ‚Ä¢ Preserves data distribution better than mean\n",
      "   ‚Ä¢ Less sensitive to extreme values\n",
      "\n",
      "üè∑Ô∏è CATEGORICAL COLUMNS ‚Üí Fill with Mode\n",
      "   ‚Ä¢ Why? Mode is the most frequent value\n",
      "   ‚Ä¢ Maintains categorical distribution\n",
      "   ‚Ä¢ Most logical imputation for categories\n",
      "\n",
      "üîß IMPLEMENTING IMPUTATION\n",
      "----------------------------------------\n",
      "‚úÖ No imputation needed - no missing values found\n",
      "\n",
      "‚úÖ Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Handle Missing Values\n",
    "# =============================\n",
    "print(\"üßπ HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nSTRATEGY FOR HANDLING MISSING DATA:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"üìä NUMERICAL COLUMNS ‚Üí Fill with Median\")\n",
    "print(\"   ‚Ä¢ Why? Median is robust to outliers\")\n",
    "print(\"   ‚Ä¢ Preserves data distribution better than mean\")\n",
    "print(\"   ‚Ä¢ Less sensitive to extreme values\")\n",
    "\n",
    "print(\"\\nüè∑Ô∏è CATEGORICAL COLUMNS ‚Üí Fill with Mode\")\n",
    "print(\"   ‚Ä¢ Why? Mode is the most frequent value\")\n",
    "print(\"   ‚Ä¢ Maintains categorical distribution\")\n",
    "print(\"   ‚Ä¢ Most logical imputation for categories\")\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"\\nüîß IMPLEMENTING IMPUTATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Track imputation details\n",
    "imputation_details = []\n",
    "\n",
    "# Handle numerical columns\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        imputation_details.append(f\"   ‚Ä¢ {col}: {missing_count} missing ‚Üí Median: {median_val:.2f}\")\n",
    "\n",
    "# Handle categorical columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        df[col].fillna(mode_val, inplace=True)\n",
    "        imputation_details.append(f\"   ‚Ä¢ {col}: {missing_count} missing ‚Üí Mode: '{mode_val}'\")\n",
    "\n",
    "# Show imputation results\n",
    "if imputation_details:\n",
    "    print(\"Imputation performed on:\")\n",
    "    for detail in imputation_details:\n",
    "        print(detail)\n",
    "else:\n",
    "    print(\"‚úÖ No imputation needed - no missing values found\")\n",
    "\n",
    "print(f\"\\n‚úÖ Missing values after imputation: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459cb1a4-f8e9-4eb2-bc49-b50b404e6118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç REMOVING DUPLICATE RECORDS\n",
      "============================================================\n",
      "\n",
      "BEFORE REMOVAL:\n",
      "   ‚Ä¢ Total rows: 395\n",
      "   ‚Ä¢ Duplicate rows: 0\n",
      "   ‚Ä¢ Duplicate percentage: 0.00%\n",
      "\n",
      "AFTER REMOVAL:\n",
      "   ‚Ä¢ Total rows: 395\n",
      "   ‚Ä¢ Rows removed: 0\n",
      "   ‚Ä¢ Unique rows preserved: 395\n",
      "\n",
      "‚úÖ Duplicate check: 0 duplicates remaining\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Remove Duplicate Records\n",
    "# =================================\n",
    "print(\"üîç REMOVING DUPLICATE RECORDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store initial count\n",
    "initial_rows = len(df)\n",
    "initial_duplicates = df.duplicated().sum()\n",
    "\n",
    "print(f\"\\nBEFORE REMOVAL:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {initial_rows:,}\")\n",
    "print(f\"   ‚Ä¢ Duplicate rows: {initial_duplicates}\")\n",
    "print(f\"   ‚Ä¢ Duplicate percentage: {(initial_duplicates/initial_rows*100):.2f}%\")\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True, keep='first')\n",
    "\n",
    "# Calculate after removal\n",
    "remaining_rows = len(df)\n",
    "rows_removed = initial_rows - remaining_rows\n",
    "\n",
    "print(f\"\\nAFTER REMOVAL:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {remaining_rows:,}\")\n",
    "print(f\"   ‚Ä¢ Rows removed: {rows_removed}\")\n",
    "print(f\"   ‚Ä¢ Unique rows preserved: {remaining_rows:,}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Duplicate check: {df.duplicated().sum()} duplicates remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe07e9b-8257-46cd-8672-7c867d5eb17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù STANDARDIZING COLUMN NAMES\n",
      "============================================================\n",
      "\n",
      "STANDARDIZATION RULES:\n",
      "----------------------------------------\n",
      "1. Convert to lowercase\n",
      "2. Replace spaces with underscores\n",
      "3. Remove special characters\n",
      "4. Ensure consistent naming convention\n",
      "\n",
      "ORIGINAL COLUMN NAMES (33 columns):\n",
      "    1. school\n",
      "    2. sex\n",
      "    3. age\n",
      "    4. address\n",
      "    5. famsize\n",
      "    6. Pstatus\n",
      "    7. Medu\n",
      "    8. Fedu\n",
      "    9. Mjob\n",
      "   10. Fjob\n",
      "   11. reason\n",
      "   12. guardian\n",
      "   13. traveltime\n",
      "   14. studytime\n",
      "   15. failures\n",
      "   16. schoolsup\n",
      "   17. famsup\n",
      "   18. paid\n",
      "   19. activities\n",
      "   20. nursery\n",
      "   21. higher\n",
      "   22. internet\n",
      "   23. romantic\n",
      "   24. famrel\n",
      "   25. freetime\n",
      "   26. goout\n",
      "   27. Dalc\n",
      "   28. Walc\n",
      "   29. health\n",
      "   30. absences\n",
      "   31. G1\n",
      "   32. G2\n",
      "   33. G3\n",
      "\n",
      "STANDARDIZED COLUMN NAMES:\n",
      "    1. school (unchanged)\n",
      "    2. sex (unchanged)\n",
      "    3. age (unchanged)\n",
      "    4. address (unchanged)\n",
      "    5. famsize (unchanged)\n",
      "    6. 'Pstatus' ‚Üí 'pstatus'\n",
      "    7. 'Medu' ‚Üí 'medu'\n",
      "    8. 'Fedu' ‚Üí 'fedu'\n",
      "    9. 'Mjob' ‚Üí 'mjob'\n",
      "   10. 'Fjob' ‚Üí 'fjob'\n",
      "   11. reason (unchanged)\n",
      "   12. guardian (unchanged)\n",
      "   13. traveltime (unchanged)\n",
      "   14. studytime (unchanged)\n",
      "   15. failures (unchanged)\n",
      "   16. schoolsup (unchanged)\n",
      "   17. famsup (unchanged)\n",
      "   18. paid (unchanged)\n",
      "   19. activities (unchanged)\n",
      "   20. nursery (unchanged)\n",
      "   21. higher (unchanged)\n",
      "   22. internet (unchanged)\n",
      "   23. romantic (unchanged)\n",
      "   24. famrel (unchanged)\n",
      "   25. freetime (unchanged)\n",
      "   26. goout (unchanged)\n",
      "   27. 'Dalc' ‚Üí 'dalc'\n",
      "   28. 'Walc' ‚Üí 'walc'\n",
      "   29. health (unchanged)\n",
      "   30. absences (unchanged)\n",
      "   31. 'G1' ‚Üí 'g1'\n",
      "   32. 'G2' ‚Üí 'g2'\n",
      "   33. 'G3' ‚Üí 'g3'\n",
      "\n",
      "‚úÖ Column names standardized: 33 columns\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Standardize Column Names\n",
    "# =================================\n",
    "print(\"üìù STANDARDIZING COLUMN NAMES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nSTANDARDIZATION RULES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. Convert to lowercase\")\n",
    "print(\"2. Replace spaces with underscores\")\n",
    "print(\"3. Remove special characters\")\n",
    "print(\"4. Ensure consistent naming convention\")\n",
    "\n",
    "# Store original column names\n",
    "original_columns = df.columns.tolist()\n",
    "\n",
    "print(f\"\\nORIGINAL COLUMN NAMES ({len(original_columns)} columns):\")\n",
    "for i, col in enumerate(original_columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "# Standardize column names\n",
    "def standardize_column_name(name):\n",
    "    \"\"\"Convert column name to standard format.\"\"\"\n",
    "    name = str(name).lower()  # Lowercase\n",
    "    name = name.replace(' ', '_')  # Replace spaces\n",
    "    name = ''.join(char for char in name if char.isalnum() or char == '_')  # Remove special chars\n",
    "    return name\n",
    "\n",
    "df.columns = [standardize_column_name(col) for col in df.columns]\n",
    "\n",
    "print(f\"\\nSTANDARDIZED COLUMN NAMES:\")\n",
    "for i, (old, new) in enumerate(zip(original_columns, df.columns), 1):\n",
    "    if old != new:\n",
    "        print(f\"   {i:2d}. '{old}' ‚Üí '{new}'\")\n",
    "    else:\n",
    "        print(f\"   {i:2d}. {new} (unchanged)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Column names standardized: {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35cc523e-3eaf-429c-89ec-63d047e8994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ ENCODING CATEGORICAL VARIABLES\n",
      "============================================================\n",
      "\n",
      "ENCODING STRATEGY:\n",
      "----------------------------------------\n",
      "üìä Simple Label Encoding\n",
      "   ‚Ä¢ Why? Converts categories to numerical format\n",
      "   ‚Ä¢ Preserves ordinal relationships where they exist\n",
      "   ‚Ä¢ Required for most machine learning algorithms\n",
      "   ‚Ä¢ Mapping saved for interpretability\n",
      "\n",
      "Categorical columns to encode (17):\n",
      "    1. school (2 unique values)\n",
      "    2. sex (2 unique values)\n",
      "    3. address (2 unique values)\n",
      "    4. famsize (2 unique values)\n",
      "    5. pstatus (2 unique values)\n",
      "    6. mjob (5 unique values)\n",
      "    7. fjob (5 unique values)\n",
      "    8. reason (4 unique values)\n",
      "    9. guardian (3 unique values)\n",
      "   10. schoolsup (2 unique values)\n",
      "   11. famsup (2 unique values)\n",
      "   12. paid (2 unique values)\n",
      "   13. activities (2 unique values)\n",
      "   14. nursery (2 unique values)\n",
      "   15. higher (2 unique values)\n",
      "   16. internet (2 unique values)\n",
      "   17. romantic (2 unique values)\n",
      "\n",
      "üîß ENCODING PROCESS:\n",
      "----------------------------------------\n",
      "\n",
      "school:\n",
      "   'GP' ‚Üí 0\n",
      "   'MS' ‚Üí 1\n",
      "\n",
      "sex:\n",
      "   'F' ‚Üí 0\n",
      "   'M' ‚Üí 1\n",
      "\n",
      "address:\n",
      "   'R' ‚Üí 0\n",
      "   'U' ‚Üí 1\n",
      "\n",
      "famsize:\n",
      "   'GT3' ‚Üí 0\n",
      "   'LE3' ‚Üí 1\n",
      "\n",
      "pstatus:\n",
      "   'A' ‚Üí 0\n",
      "   'T' ‚Üí 1\n",
      "\n",
      "mjob:\n",
      "   'at_home' ‚Üí 0\n",
      "   'health' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "   'services' ‚Üí 3\n",
      "   'teacher' ‚Üí 4\n",
      "\n",
      "fjob:\n",
      "   'at_home' ‚Üí 0\n",
      "   'health' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "   'services' ‚Üí 3\n",
      "   'teacher' ‚Üí 4\n",
      "\n",
      "reason:\n",
      "   'course' ‚Üí 0\n",
      "   'home' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "   'reputation' ‚Üí 3\n",
      "\n",
      "guardian:\n",
      "   'father' ‚Üí 0\n",
      "   'mother' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "\n",
      "schoolsup:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "famsup:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "paid:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "activities:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "nursery:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "higher:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "internet:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "romantic:\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "‚úÖ Encoding complete. 17 columns encoded.\n",
      "\n",
      "üìã ENCODING MAPPING SUMMARY:\n",
      "\n",
      "school: 2 categories\n",
      "   'GP' ‚Üí 0\n",
      "   'MS' ‚Üí 1\n",
      "\n",
      "sex: 2 categories\n",
      "   'F' ‚Üí 0\n",
      "   'M' ‚Üí 1\n",
      "\n",
      "address: 2 categories\n",
      "   'R' ‚Üí 0\n",
      "   'U' ‚Üí 1\n",
      "\n",
      "famsize: 2 categories\n",
      "   'GT3' ‚Üí 0\n",
      "   'LE3' ‚Üí 1\n",
      "\n",
      "pstatus: 2 categories\n",
      "   'A' ‚Üí 0\n",
      "   'T' ‚Üí 1\n",
      "\n",
      "mjob: 5 categories\n",
      "   'at_home' ‚Üí 0\n",
      "   'health' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "   ... and 2 more\n",
      "\n",
      "fjob: 5 categories\n",
      "   'at_home' ‚Üí 0\n",
      "   'health' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "   ... and 2 more\n",
      "\n",
      "reason: 4 categories\n",
      "   'course' ‚Üí 0\n",
      "   'home' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "   ... and 1 more\n",
      "\n",
      "guardian: 3 categories\n",
      "   'father' ‚Üí 0\n",
      "   'mother' ‚Üí 1\n",
      "   'other' ‚Üí 2\n",
      "\n",
      "schoolsup: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "famsup: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "paid: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "activities: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "nursery: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "higher: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "internet: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "romantic: 2 categories\n",
      "   'no' ‚Üí 0\n",
      "   'yes' ‚Üí 1\n",
      "\n",
      "‚úÖ Data types updated to 'category' for encoded columns\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Encode Categorical Variables\n",
    "# ====================================\n",
    "print(\"üî¢ ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nENCODING STRATEGY:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"üìä Simple Label Encoding\")\n",
    "print(\"   ‚Ä¢ Why? Converts categories to numerical format\")\n",
    "print(\"   ‚Ä¢ Preserves ordinal relationships where they exist\")\n",
    "print(\"   ‚Ä¢ Required for most machine learning algorithms\")\n",
    "print(\"   ‚Ä¢ Mapping saved for interpretability\")\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nCategorical columns to encode ({len(categorical_cols)}):\")\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    unique_vals = df[col].nunique()\n",
    "    print(f\"   {i:2d}. {col} ({unique_vals} unique values)\")\n",
    "\n",
    "# Create dictionary to store mappings\n",
    "encoding_mappings = {}\n",
    "\n",
    "print(\"\\nüîß ENCODING PROCESS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Get unique values and create mapping\n",
    "    unique_values = df[col].unique()\n",
    "    encoding_map = {value: idx for idx, value in enumerate(sorted(unique_values))}\n",
    "    encoding_mappings[col] = encoding_map\n",
    "    \n",
    "    # Apply encoding\n",
    "    df[col] = df[col].map(encoding_map)\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    for value, code in encoding_map.items():\n",
    "        print(f\"   '{value}' ‚Üí {code}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Encoding complete. {len(categorical_cols)} columns encoded.\")\n",
    "print(\"\\nüìã ENCODING MAPPING SUMMARY:\")\n",
    "for col, mapping in encoding_mappings.items():\n",
    "    print(f\"\\n{col}: {len(mapping)} categories\")\n",
    "    # Show first few mappings for readability\n",
    "    for i, (key, value) in enumerate(list(mapping.items())[:3]):\n",
    "        print(f\"   '{key}' ‚Üí {value}\")\n",
    "    if len(mapping) > 3:\n",
    "        print(f\"   ... and {len(mapping) - 3} more\")\n",
    "\n",
    "# Convert encoded columns to appropriate data type\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "print(f\"\\n‚úÖ Data types updated to 'category' for encoded columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4da5a4-a684-4519-b489-7fe116bc99e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FINAL DATA QUALITY VERIFICATION\n",
      "============================================================\n",
      "\n",
      "1. DATASET STRUCTURE AFTER CLEANING\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   school      395 non-null    category\n",
      " 1   sex         395 non-null    category\n",
      " 2   age         395 non-null    int64   \n",
      " 3   address     395 non-null    category\n",
      " 4   famsize     395 non-null    category\n",
      " 5   pstatus     395 non-null    category\n",
      " 6   medu        395 non-null    int64   \n",
      " 7   fedu        395 non-null    int64   \n",
      " 8   mjob        395 non-null    category\n",
      " 9   fjob        395 non-null    category\n",
      " 10  reason      395 non-null    category\n",
      " 11  guardian    395 non-null    category\n",
      " 12  traveltime  395 non-null    int64   \n",
      " 13  studytime   395 non-null    int64   \n",
      " 14  failures    395 non-null    int64   \n",
      " 15  schoolsup   395 non-null    category\n",
      " 16  famsup      395 non-null    category\n",
      " 17  paid        395 non-null    category\n",
      " 18  activities  395 non-null    category\n",
      " 19  nursery     395 non-null    category\n",
      " 20  higher      395 non-null    category\n",
      " 21  internet    395 non-null    category\n",
      " 22  romantic    395 non-null    category\n",
      " 23  famrel      395 non-null    int64   \n",
      " 24  freetime    395 non-null    int64   \n",
      " 25  goout       395 non-null    int64   \n",
      " 26  dalc        395 non-null    int64   \n",
      " 27  walc        395 non-null    int64   \n",
      " 28  health      395 non-null    int64   \n",
      " 29  absences    395 non-null    int64   \n",
      " 30  g1          395 non-null    int64   \n",
      " 31  g2          395 non-null    int64   \n",
      " 32  g3          395 non-null    int64   \n",
      "dtypes: category(17), int64(16)\n",
      "memory usage: 58.4 KB\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Final Data Quality Checks\n",
    "# ==================================\n",
    "print(\"‚úÖ FINAL DATA QUALITY VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. DATASET STRUCTURE AFTER CLEANING\")\n",
    "print(\"-\" * 40)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930d646b-b078-474d-94bb-0ad94bf46f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. MISSING VALUES FINAL CHECK\n",
      "----------------------------------------\n",
      "‚úÖ PERFECT: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. MISSING VALUES FINAL CHECK\")\n",
    "print(\"-\" * 40)\n",
    "missing_final = df.isnull().sum().sum()\n",
    "if missing_final == 0:\n",
    "    print(f\"‚úÖ PERFECT: {missing_final} missing values\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: {missing_final} missing values remain\")\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac650f4-10f7-4b12-9019-aa3c5c97954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. DATA PREVIEW AFTER CLEANING\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>pstatus</th>\n",
       "      <th>medu</th>\n",
       "      <th>fedu</th>\n",
       "      <th>mjob</th>\n",
       "      <th>fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>dalc</th>\n",
       "      <th>walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize pstatus  medu  fedu mjob fjob  ... famrel  \\\n",
       "0      0   0   18       1       0       0     4     4    0    4  ...      4   \n",
       "1      0   0   17       1       0       1     1     1    0    2  ...      5   \n",
       "2      0   0   15       1       1       1     1     1    0    2  ...      4   \n",
       "3      0   0   15       1       0       1     4     2    1    3  ...      3   \n",
       "4      0   0   16       1       0       1     3     3    2    2  ...      4   \n",
       "\n",
       "  freetime  goout  dalc  walc health absences  g1  g2  g3  \n",
       "0        3      4     1     1      3        6   5   6   6  \n",
       "1        3      3     1     1      3        4   5   5   6  \n",
       "2        3      2     2     3      3       10   7   8  10  \n",
       "3        2      2     1     1      5        2  15  14  15  \n",
       "4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n3. DATA PREVIEW AFTER CLEANING\")\n",
    "print(\"-\" * 40)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9928b78-aa7d-499f-bb52-10f180d52a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAVING CLEANED DATASET\n",
      "============================================================\n",
      "\n",
      "SAVE LOCATION:\n",
      "   Directory: data/cleaned/\n",
      "   Filename: student_performance_cleaned.csv\n",
      "   Full path: ../data/cleaned/student_performance_cleaned.csv\n",
      "\n",
      "‚úÖ SUCCESS: Cleaned data saved to ../data/cleaned/student_performance_cleaned.csv\n",
      "   ‚Ä¢ File size: 27,939 bytes\n",
      "   ‚Ä¢ Rows saved: 395\n",
      "   ‚Ä¢ Columns saved: 33\n",
      "\n",
      "üìä CLEANING PROCESS SUMMARY\n",
      "============================================================\n",
      "Initial shape: 395 √ó 33\n",
      "Final shape:   395 √ó 33\n",
      "Rows removed:  0 (duplicates)\n",
      "Columns encoded: 17\n",
      "Missing values: 0\n",
      "\n",
      "‚úÖ Data cleaning complete! Ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Save Cleaned Data\n",
    "# ==========================\n",
    "print(\"üíæ SAVING CLEANED DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define save path\n",
    "save_path = '../data/cleaned/student_performance_cleaned.csv'\n",
    "\n",
    "print(f\"\\nSAVE LOCATION:\")\n",
    "print(f\"   Directory: data/cleaned/\")\n",
    "print(f\"   Filename: student_performance_cleaned.csv\")\n",
    "print(f\"   Full path: {save_path}\")\n",
    "\n",
    "# Ensure directory exists\n",
    "import os\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "try:\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"\\n‚úÖ SUCCESS: Cleaned data saved to {save_path}\")\n",
    "    print(f\"   ‚Ä¢ File size: {os.path.getsize(save_path):,} bytes\")\n",
    "    print(f\"   ‚Ä¢ Rows saved: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Columns saved: {len(df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR: Failed to save file - {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nüìä CLEANING PROCESS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Initial shape: {initial_rows:,} √ó {len(original_columns)}\")\n",
    "print(f\"Final shape:   {len(df):,} √ó {len(df.columns)}\")\n",
    "print(f\"Rows removed:  {initial_rows - len(df)} (duplicates)\")\n",
    "print(f\"Columns encoded: {len(categorical_cols)}\")\n",
    "print(f\"Missing values: 0\")\n",
    "print(f\"\\n‚úÖ Data cleaning complete! Ready for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da89a1-5dfd-453c-9052-e4625e8d907b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
